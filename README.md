# ğŸš€ Store Item Demand Forecasting Project

A full end-to-end machine learning pipeline for demand forecasting, including data validation, feature engineering, model training, rolling backtesting, and Dockerized deployment.

## ğŸ“Œ 1. Project Summary

This project implements a complete forecasting system for the Store Item Demand Forecasting dataset (Kaggle). It follows real-world machine learning engineering practices:
- **Raw data ingestion & validation** (pandera schemas)
- **Feature engineering pipeline** (calendar features, lag features, rolling statistics, cyclic seasonality)
- **Model training** using **LightGBM** and **CatBoost**
- **Rolling-origin backtesting** to evaluate performance over time
- **Baselines** including naive-1, naive-7, and naive-28
- **Batch inference CLI** for generating predictions
- **Dockerized deployment** for reproducible forecasting anywhere

The final system demonstrates strong forecasting performance (~4.08 MAE with CatBoost) and is structured the same way production ML systems are built in industry.

--- 

## ğŸ“‚ 2. Project Structure
forecast-studio/

â”‚

â”œâ”€â”€ data/

â”‚   â”œâ”€â”€ raw/                 # Original Kaggle dataset (not versioned)

â”‚   â”œâ”€â”€ processed/           # Engineered features (parquet files)

â”‚

â”œâ”€â”€ models/

â”‚   â””â”€â”€ catboost_baseline.pkl   # Saved model artifacts (ignored by Git)

â”‚

â”œâ”€â”€ reports/

â”‚   â”œâ”€â”€ backtest_rolling_windows.csv

â”‚   â”œâ”€â”€ backtest_catboost_rolling_windows.csv

â”‚   â””â”€â”€ predictions.csv        # Saved forecast outputs

â”‚

â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ features/

â”‚   â”‚   â”œâ”€â”€ config.py              # Global configuration paths & constants

â”‚   â”‚   â”œâ”€â”€ schema.py          # Pandera schemas for raw & processed data

â”‚   â”‚   â”œâ”€â”€ make_features.py   # Main feature engineering pipeline

â”‚   â”‚

â”‚   â”œâ”€â”€ models/

â”‚   â”‚   â”œâ”€â”€ baseline.py        # LightGBM training logic

â”‚   â”‚   â”œâ”€â”€ catboost_baseline.py

â”‚   â”‚   â””â”€â”€ predict_catboost.py # CLI prediction tool

â”‚   â”‚

â”‚   â”œâ”€â”€ eval/

â”‚   â”‚   â”œâ”€â”€ backtest.py        # Rolling-origin backtesting (LightGBM)

â”‚   â”‚   â””â”€â”€ backtest_catboost.py

â”‚

â”œâ”€â”€ Dockerfile                 # Dockerized forecasting environment

â”œâ”€â”€ .dockerignore

â”œâ”€â”€ .gitignore

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md

## â–¶ï¸ 3. How to Download & Run the Project
### Step 1 â€” Clone the repo

*git clone https://github.com/your-username/repo-name.git*

*cd repo-name*

### Step 2 â€” Create a virtual environment

*python -m venv venv*

*source venv/bin/activate*      # Mac/Linux

*venv\Scripts\activate*         # Windows

### Step 3 â€” Install dependencies

*pip install -r requirements.txt*

### Step 4 â€” Add the dataset

**Download the Store Item Demand Forecasting dataset from Kaggle and place:**

train.csv â†’ data/raw/train.csv

test.csv  â†’ data/raw/test.csv

### Step 5 â€” Generate features

*python -m src.features.make_features*


This will output:

data/processed/train_features.parquet

data/processed/test_features.parquet

### Step 6 â€” Train the model

**CatBoost (best-performing):**

*python -m src.models.train_catboost*


**LightGBM (baseline):**

*python -m src.models.train_baseline*

### Step 7 â€” Run rolling backtests

**CatBoost:**

*python -m src.eval.backtest_catboost*


**LightGBM:**

*python -m src.eval.backtest*


Backtest results appear in reports/.

### Step 8 â€” Generate predictions (batch inference)

*python -m src.models.predict_catboost* \

  *--model-path models/catboost_baseline.pkl* \
  
  *--input-path data/processed/test_features.parquet* \
  
  *--output-path reports/predictions.csv*

### ğŸ³ 4. Running the Project with Docker

Build the Docker image

*docker build -t store-forecast .*


Run predictions inside Docker

docker run --rm -v "${PWD}:/app" store-forecast \

  --model-path models/catboost_baseline.pkl \
  
  --input-path data/processed/test_features.parquet \
  
  --output-path reports/docker_predictions.csv


Because the Dockerfile includes:

ENTRYPOINT ["python", "-m", "src.models.predict_catboost"]


the CLI works like a native tool inside Docker.

### ğŸ“Š 5. Model Performance

Average performance across multiple backtest windows:


Model,	MAE (avg),	RMSE (avg)

CatBoost,	~4.08,	~5.30

LightGBM,	~4.11,	~5.33

Naive-7,	~6.7â€“9.0	higher

Naive-28,	~7.0â€“10	higher


The model consistently outperforms:

- naive-1 baseline
- weekly seasonal naive (lag 7)
- monthly seasonal naive (lag 28)

This confirms strong and stable forecasting behavior.

## ğŸ§© 6. Key Features of This Project

âœ” Pandera schemas for robust data validation

âœ” Daily continuity checks to avoid broken time series

âœ” Lag features + rolling mean & std windows

âœ” Cyclic seasonal features (sin/cos encodings)

âœ” Holiday proximity features

âœ” Global forecasting model (shared across all store-item series)

âœ” Rolling-origin time-series backtesting

âœ” Model comparison (LightGBM vs CatBoost)

âœ” Dockerized CLI for batch predictions

âœ” Strong modular design for extensibility

## ğŸ§­ 7. Future Improvements (Roadmap)

- Add hyperparameter tuning (Optuna or Ray Tune)
- Deploy a FastAPI prediction server
- Push Docker image to GitHub Container Registry
- Build a Streamlit dashboard for visualizing forecasts

## ğŸ‘¨â€ğŸ’» 8. Author

Created by: Rheanna Pena

[GitHub](https://github.com/rjgallego)

[LinkedIn](https://www.linkedin.com/in/rheanna-pena-aa0007110/)
